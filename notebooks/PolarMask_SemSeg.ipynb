{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "import numpy as np\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from mmcv.parallel import collate, scatter\n",
    "\n",
    "from mmdet.datasets.pipelines import Compose\n",
    "from mmdet.core import bbox2result, bbox_mask2result\n",
    "from mmdet.datasets.coco_polar import Coco_Seg_Dataset as DATASET\n",
    "from mmdet.apis.inference import init_detector, inference_detector, show_result, LoadImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = {}\n",
    "for i in range(80):\n",
    "    COLORS[i] = (0,255,0)\n",
    "\n",
    "def get_data(img, cfg, device):\n",
    "    # build the data pipeline\n",
    "    test_pipeline = [LoadImage()] + cfg.test_pipeline[1:]\n",
    "    test_pipeline = Compose(test_pipeline)\n",
    "    # prepare data\n",
    "    data = dict(img=img)\n",
    "    data = test_pipeline(data)\n",
    "    data = scatter(collate([data], samples_per_gpu=1), [device])[0]\n",
    "    return data\n",
    "\n",
    "def draw_semseg(image, mask):\n",
    "    image_ = image.copy()\n",
    "    _mask = np.zeros_like(image_)\n",
    "    _mask[mask==1,...] = (0,0,255)\n",
    "    image_ = cv2.add(image_, _mask)\n",
    "    return image_\n",
    "\n",
    "def draw_bboxes(image, bboxes, labels, scores=None, thick=2):\n",
    "    image_ = image.copy()\n",
    "\n",
    "    if scores is not None:\n",
    "        for (left, top, right, bottom), label, score in zip(bboxes, labels, scores):\n",
    "            left = int(left); top = int(top); right = int(right); bottom = int(bottom)\n",
    "            cv2.rectangle(image_, (left, top), (right, bottom), COLORS[label], thick)\n",
    "            text = \"%s_%.2f\" % (DATASET.CLASSES[label], score)\n",
    "            cv2.putText(image_, text, (left-10, top-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[label], 2)\n",
    "\n",
    "    else:\n",
    "        for (left, top, right, bottom), label in zip(bboxes, labels):\n",
    "            left = int(left); top = int(top); right = int(right); bottom = int(bottom)\n",
    "            cv2.rectangle(image_, (left, top), (right, bottom), COLORS[label], thick)\n",
    "            cv2.putText(image_, DATASET.CLASSES[label], (left-10, top-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[label], 2)\n",
    "\n",
    "    return image_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"../ccdetection/configs/polarmask/polar_b1_semseg.py\"\n",
    "checkpoint = \"/home/member/Workspace/thuync/checkpoints/polar_b1_semseg/epoch_10.pth\"\n",
    "# img_file = \"/home/member/Workspace/dataset/coco/images/val2017/000000397133.jpg\"\n",
    "img_file = \"/home/member/Workspace/thuync/ccdetpose/mmdetection/demo/demo.jpg\"\n",
    "out_file = \"/home/member/Workspace/thuync/checkpoints/polar_b1_semseg/debug.png\"\n",
    "\n",
    "model = init_detector(config, checkpoint=checkpoint, device='cuda')\n",
    "data = get_data(img_file, model.cfg, next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.3\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Prepare data\n",
    "    img = data['img'][0]\n",
    "    img_meta = data['img_meta'][0]\n",
    "    print(img_meta[0].keys())\n",
    "    ori_shape = img_meta[0]['ori_shape']\n",
    "    img_h, img_w, _ = ori_shape\n",
    "\n",
    "    # Get instance\n",
    "    x = model.extract_feat(img)\n",
    "    bbox_outs = model.bbox_head(x)\n",
    "    bbox_pred = bbox_outs + (img_meta, model.test_cfg, True)\n",
    "    bboxes, labels, masks = model.bbox_head.get_bboxes(*bbox_pred)[0]\n",
    "\n",
    "    # Filter\n",
    "    bboxes = bboxes.cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    indicator = (bboxes[:,-1] > threshold)\n",
    "    bboxes = bboxes[indicator][:,:-1]\n",
    "    labels = labels[indicator]\n",
    "\n",
    "    # Transform instance mask\n",
    "    _masks = []\n",
    "    for i in range(masks.shape[0]):\n",
    "        im_mask = np.zeros((img_h, img_w), dtype=np.uint8)\n",
    "        mask = [masks[i].transpose(1,0).unsqueeze(1).int().data.cpu().numpy()]\n",
    "        im_mask = cv2.drawContours(im_mask, mask, -1,1,-1)\n",
    "        _masks.append(im_mask)\n",
    "    masks = np.stack(_masks)\n",
    "    masks = masks[indicator]\n",
    "\n",
    "    # Get semantic\n",
    "    mask_pred = model.semseg_head(x)\n",
    "    mask_pred = model.semseg_head.get_seg_masks(mask_pred, ori_shape, scale_factor=1.0, rescale=False, threshold=0.5)\n",
    "    foreground = mask_pred[0,0].astype('uint8')\n",
    "\n",
    "print(\"bboxes:\", bboxes.shape)\n",
    "print(\"labels:\", labels.shape)\n",
    "print(\"masks:\", masks.shape)\n",
    "print(\"foregrounds:\", foreground.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(img_file)[...,::-1]\n",
    "_masks = masks.sum(axis=0).clip(0,1).astype('uint8')\n",
    "_masks = cv2.resize(_masks, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "foreground = cv2.resize(foreground, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "image_bbox = draw_bboxes(image, bboxes, labels)\n",
    "image_sem = draw_semseg(image_bbox, foreground)\n",
    "image_ins = draw_semseg(image_bbox, _masks)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(2,1,1); plt.imshow(image_sem)\n",
    "plt.subplot(2,1,2); plt.imshow(image_ins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_score = bbox_outs[0]\n",
    "centerness = bbox_outs[2]\n",
    "\n",
    "sc_thres = 0.05\n",
    "cls_scores = []\n",
    "for score, center in zip(cls_score, centerness):\n",
    "    score = score.sigmoid() * center\n",
    "    score = (score>sc_thres).float().cpu().numpy()\n",
    "    score = score[0].sum(axis=0).clip(0,1).astype('uint8')\n",
    "    score = cv2.resize(score, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "    cls_scores.append(score)\n",
    "cls_scores = np.stack(cls_scores).sum(axis=0).clip(0,1)\n",
    "print(cls_scores.shape)\n",
    "\n",
    "image_p3 = draw_semseg(image_bbox, cls_scores)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(image_p3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
